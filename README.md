Water Usage Prediction with Deep Learning
Project Overview
This project focuses on predicting water usage in residential units using a deep learning model. It leverages historical water meter data, combined with building and unit-specific attributes, and temporal features to forecast future water consumption. The goal is to provide accurate predictions that can aid in better resource management, anomaly detection (e.g., leaks), and improved tenant awareness of water consumption.

The project involves extensive data preparation and cleaning, feature engineering, and the development of a neural network model using TensorFlow/Keras.

Features
Data Aggregation: Combines water usage data from multiple monthly CSV files into a single, comprehensive dataset.

Robust Data Cleaning: Handles missing values, converts data types, and processes categorical and numerical features.

Feature Engineering: Creates new features from existing data, such as Date, Hour, DayOfWeek, and Month from timestamps, to capture temporal patterns.

Anomaly Detection (Implied): By predicting Use (gal), significant deviations between actual and predicted usage can indicate potential leaks or unusual consumption patterns.

Deep Learning Model: Implements a neural network with a mixed-input architecture (combining numerical and embedding layers for categorical features) for improved prediction accuracy.

Model Evaluation: Evaluates the model's performance using metrics like Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R² Score.

Project Structure
capstone_updated_2_part_ml.ipynb: The main Jupyter Notebook containing all the code for data loading, cleaning, preprocessing, model building, training, and evaluation.

2025-01 - Native Data for Models-January(January 2025).csv: Example raw data file (similarly for Feb, March, April). These files are expected to be in the same directory as the notebook.

combined_data.csv: An intermediate CSV file generated by combining the monthly raw data files.

Setup and Installation
To run this project, you'll need Python and the following libraries. It's recommended to use a virtual environment.

1. Clone the repository:
git clone <repository_url>
cd water-usage-prediction

2. Create and activate a virtual environment (optional but recommended):
python -m venv venv
# On Windows
.\venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate

3. Install the required packages:
pip install pandas numpy matplotlib seaborn tensorflow scikit-learn

4. Data Preparation:
Place your raw monthly CSV data files (e.g., 2025-01 - Native Data for Models-January(January 2025).csv, 2025-02 - Native Data for Models-February(1).csv, etc.) in the root directory of the project. The notebook will automatically combine them.

Usage
Open the Jupyter Notebook:

jupyter notebook capstone_updated_2_part_ml.ipynb

Run all cells: Execute the cells sequentially in the notebook.

The notebook will first combine the monthly CSV files into combined_data.csv.

It will then perform data cleaning, feature engineering, and split the data into training, validation, and testing sets.

The deep learning model will be built and trained.

Finally, the model will be evaluated, and the performance metrics will be printed.

Data Description
The dataset consists of water meter readings and associated property information. Key columns include:

Building Name: Identifier for the building.

Unit: Unit number within the building.

Meter #: Unique identifier for the water meter.

Time Adjusted by Property: Timestamp of the reading.

Use (gal): Water consumption in gallons during the interval. (Target Variable)

Accu Reading (gal): Accumulated water reading.

Water Temp (gal): Water temperature.

Signal Strength: Signal strength of the meter.

Battery(Volts): Battery voltage of the meter.

Unit Type, Unit Type Matrix, Unit Class: Categorical features describing the unit type.

No. Bedrooms, No. Full Baths, No. Half Baths, Stories, Unit Size (Sf): Numerical features describing unit characteristics.

Location, Status: Additional categorical features.

Date, Hour, DayOfWeek, Month: Engineered temporal features.

Deep Learning Model Architecture
The model is a neural network built with TensorFlow/Keras, designed to handle both numerical and categorical features effectively.

Input Layers:

Numeric Input: For scaled numerical features (e.g., Water Temp (gal), Battery(Volts), Signal Strength, Accu Reading (gal), Unit Size (Sf), No. Bedrooms, No. Full Baths, No. Half Baths, Stories, Hour, DayOfWeek, Month).

Unit Type Input: For categorical features (Unit Type, Location, Status, Unit Type Matrix, Unit Class, Building Name). Each categorical feature goes through an Embedding layer to convert sparse categorical data into dense vectors, followed by Flatten.

Concatenation: The outputs from the numerical input branch and all embedding branches are concatenated.

Dense Layers: A series of Dense layers with ReLU activation and Dropout for regularization are used to learn complex patterns. BatchNormalization is applied to stabilize and accelerate training.

Output Layer: A single Dense neuron with linear activation for regression, predicting Use (gal).

Optimization:

Optimizer: Adam

Loss Function: Mean Squared Error (MSE)

Callbacks:

EarlyStopping: Monitors validation loss and stops training if it doesn't improve for a specified patience (e.g., 10 epochs).

ReduceLROnPlateau: Reduces the learning rate when validation loss plateaus.

Model Performance
The model's performance is evaluated using the following metrics on the test set:

Mean Absolute Error (MAE): Measures the average magnitude of the errors in a set of predictions, without considering their direction.

Root Mean Squared Error (RMSE): Measures the square root of the average of the squared errors. It gives a relatively high weight to large errors.

R² Score: Represents the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R² indicates a better fit.

The output from the notebook will display these metrics. For example:

MAE: 0.27
R² Score: 96.78

(The actual values will depend on the model training and data.)

Contributing
Contributions are welcome! If you have suggestions for improvements, new features, or bug fixes, please open an issue or submit a pull request.

License
This project is open-source and available under the MIT License.
